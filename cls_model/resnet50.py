import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, Subset
import torchvision.transforms as transforms
import torchvision.models as models
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import cv2
import os
import random
from PIL import Image
from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, f1_score
from tqdm import tqdm

# ==========================================
# âš™ï¸ ì„¤ì •
# ==========================================
DATA_ROOT = "/mnt/hdd/medsam/dataset" 
OUTPUT_DIR = "tb_results_resnet"
MODEL_SAVE_PATH = os.path.join(OUTPUT_DIR, "best_resnet50.pth")
EXCEL_SAVE_PATH = os.path.join(OUTPUT_DIR, "resnet_test_result.xlsx")
CAM_SAVE_DIR = os.path.join(OUTPUT_DIR, "grad_cam_images")

BATCH_SIZE = 16
LEARNING_RATE = 1e-4
NUM_EPOCHS = 100 # Early Stoppingì´ ìˆìœ¼ë¯€ë¡œ ì—í­ì„ ë„‰ë„‰í•˜ê²Œ(50~100) ì¡ì•„ë„ ë©ë‹ˆë‹¤.
PATIENCE = 5     # 5ë²ˆ ì—°ì†ìœ¼ë¡œ Lossê°€ ì•ˆ ì¤„ì–´ë“¤ë©´ ì¢…ë£Œ
IMG_SIZE = 256
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

os.makedirs(CAM_SAVE_DIR, exist_ok=True)

# ==========================================
# ğŸ“‚ ë°ì´í„°ì…‹ & ë°¸ëŸ°ìŠ¤ ë¶„í• 
# ==========================================
class CXRDataset(Dataset):
    def __init__(self, root_dir, transform=None, mode='train'):
        self.root_dir = root_dir
        self.transform = transform
        self.image_paths = []
        self.labels = []
        self.filenames = []
        
        self.class_map = {'normal': 0, 'tuberculosis': 1}
        target_dir = os.path.join(root_dir, mode) if os.path.exists(os.path.join(root_dir, mode)) else root_dir
        
        for class_name, label in self.class_map.items():
            class_path = os.path.join(target_dir, class_name)
            if not os.path.exists(class_path): continue
            
            files = [f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
            for f in files:
                self.image_paths.append(os.path.join(class_path, f))
                self.labels.append(label)
                self.filenames.append(f)

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        path = self.image_paths[idx]
        label = self.labels[idx]
        filename = self.filenames[idx]
        try:
            image = Image.open(path).convert("RGB")
        except:
            image = Image.new('RGB', (IMG_SIZE, IMG_SIZE))
        
        if self.transform:
            image = self.transform(image)
        return image, torch.tensor(label, dtype=torch.long), filename, path

def create_balanced_split(dataset, val_count_per_class=250):
    indices = list(range(len(dataset)))
    labels = dataset.labels
    
    idx_normal = [i for i, label in enumerate(labels) if label == 0]
    idx_tuber = [i for i, label in enumerate(labels) if label == 1]
    
    random.shuffle(idx_normal)
    random.shuffle(idx_tuber)
    
    if len(idx_normal) < val_count_per_class or len(idx_tuber) < val_count_per_class:
        print("âš ï¸ ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ë¹„ìœ¨ ë¶„í• (8:2)ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
        return torch.utils.data.random_split(dataset, [int(len(dataset)*0.8), len(dataset)-int(len(dataset)*0.8)])

    val_indices = idx_normal[:val_count_per_class] + idx_tuber[:val_count_per_class]
    train_indices = idx_normal[val_count_per_class:] + idx_tuber[val_count_per_class:]
    
    return Subset(dataset, train_indices), Subset(dataset, val_indices)

# ==========================================
# ğŸ›‘ Early Stopping í´ë˜ìŠ¤ (ì¶”ê°€ë¨)
# ==========================================
class EarlyStopping:
    def __init__(self, patience=5, verbose=False, delta=0):
        """
        Args:
            patience (int): ê°œì„ ì´ ì—†ëŠ” ì—í­ì„ ì–¼ë§ˆë‚˜ ê¸°ë‹¤ë¦´ì§€ ì„¤ì •
            verbose (bool): Trueì¼ ê²½ìš° ë¡œê·¸ ì¶œë ¥
            delta (float): ê°œì„ ë˜ì—ˆë‹¤ê³  íŒë‹¨í•  ìµœì†Œ ë³€í™”ëŸ‰
        """
        self.patience = patience
        self.verbose = verbose
        self.counter = 0
        self.best_score = None
        self.early_stop = False
        self.val_loss_min = np.Inf
        self.delta = delta

    def __call__(self, val_loss):
        score = -val_loss

        if self.best_score is None:
            self.best_score = score
            self.val_loss_min = val_loss
        elif score < self.best_score + self.delta:
            self.counter += 1
            if self.verbose:
                print(f'   âš ï¸ EarlyStopping counter: {self.counter} out of {self.patience}')
            if self.counter >= self.patience:
                self.early_stop = True
        else:
            self.best_score = score
            self.val_loss_min = val_loss
            self.counter = 0

# ==========================================
# ğŸ§  Grad-CAM
# ==========================================
class GradCAM:
    def __init__(self, model, target_layer):
        self.model = model
        self.target_layer = target_layer
        self.gradients = None
        self.activations = None
        self.target_layer.register_forward_hook(self.save_activation)
        self.target_layer.register_full_backward_hook(self.save_gradient)

    def save_activation(self, module, input, output):
        self.activations = output

    def save_gradient(self, module, grad_input, grad_output):
        self.gradients = grad_output[0]

    def __call__(self, x):
        output = self.model(x)
        target_category = output.argmax(dim=1)
        score = output[:, target_category]
        self.model.zero_grad()
        score.backward(retain_graph=True)
        
        gradients = self.gradients.cpu().data.numpy()[0]
        activations = self.activations.cpu().data.numpy()[0]
        weights = np.mean(gradients, axis=(1, 2))
        
        cam = np.zeros(activations.shape[1:], dtype=np.float32)
        for i, w in enumerate(weights):
            cam += w * activations[i]
            
        cam = np.maximum(cam, 0)
        cam = cv2.resize(cam, (IMG_SIZE, IMG_SIZE))
        cam = cam - np.min(cam)
        cam = cam / (np.max(cam) + 1e-8)
        return cam, output

# ==========================================
# ğŸš€ í•™ìŠµ ë° ì‹¤í–‰ (Early Stopping ì ìš©)
# ==========================================
def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, patience=5):
    print(f"ğŸ”¥ í•™ìŠµ ì‹œì‘ (Device: {DEVICE}, Patience: {patience})")
    
    # Early Stopping ì´ˆê¸°í™”
    early_stopping = EarlyStopping(patience=patience, verbose=True)
    best_acc = 0.0
    
    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0
        correct, total = 0, 0
        
        # Training Loop
        train_bar = tqdm(train_loader, desc=f"Epoch [{epoch+1}/{num_epochs}] Train", leave=False)
        for images, labels, _, _ in train_bar:
            images, labels = images.to(DEVICE), labels.to(DEVICE)
            
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            
            running_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
            
            train_bar.set_postfix(loss=loss.item())
            
        train_loss = running_loss / len(train_loader)
        train_acc = 100 * correct / total

        # Validation Loop
        model.eval()
        val_loss = 0.0
        v_correct, v_total = 0, 0
        
        val_bar = tqdm(val_loader, desc=f"Epoch [{epoch+1}/{num_epochs}] Val  ", leave=False)
        with torch.no_grad():
            for images, labels, _, _ in val_bar:
                images, labels = images.to(DEVICE), labels.to(DEVICE)
                outputs = model(images)
                loss = criterion(outputs, labels)
                val_loss += loss.item()
                _, predicted = torch.max(outputs.data, 1)
                v_total += labels.size(0)
                v_correct += (predicted == labels).sum().item()
        
        avg_val_loss = val_loss / len(val_loader)
        val_acc = 100 * v_correct / v_total
        
        print(f"Epoch [{epoch+1}/{num_epochs}] "
              f"Train Loss: {train_loss:.4f} Acc: {train_acc:.2f}% | "
              f"Val Loss: {avg_val_loss:.4f} Acc: {val_acc:.2f}%")
        
        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥ (Accuracy ê¸°ì¤€)
        if val_acc > best_acc:
            best_acc = val_acc
            torch.save(model.state_dict(), MODEL_SAVE_PATH)
            print(f"    --> ğŸ‰ Best Model Saved (Acc: {best_acc:.2f}%)")
            
        # [Early Stopping ì²´í¬] (Validation Loss ê¸°ì¤€)
        early_stopping(avg_val_loss)
        if early_stopping.early_stop:
            print("ğŸ›‘ Early Stopping triggered! í•™ìŠµì„ ì¡°ê¸° ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

def evaluate(model, test_loader):
    model.eval()
    
    # ResNet50 Target Layer
    grad_cam = GradCAM(model, model.layer4[-1])
    
    results = []
    labels_list, preds_list, probs_list = [], [], []
    
    print("\nğŸ” ì¶”ë¡  ë° ì‹œê°í™” ì§„í–‰ ì¤‘...")
    test_bar = tqdm(enumerate(test_loader), total=len(test_loader), desc="Inference")
    
    for i, (images, labels, fname, fpath) in test_bar:
        images = images.to(DEVICE)
        
        heatmap, logits = grad_cam(images)
        probs = torch.softmax(logits, dim=1)
        prob_tb = probs[0][1].item()
        pred = logits.argmax(dim=1).item()
        
        labels_list.append(labels.item())
        probs_list.append(prob_tb)
        preds_list.append(pred)
        
        # Grad-CAM ì €ì¥
        res_img = np.vstack([np.zeros((30, IMG_SIZE, 3), np.uint8), 
                             cv2.addWeighted(cv2.resize(cv2.imread(fpath[0]), (IMG_SIZE, IMG_SIZE)), 0.6, 
                                             cv2.applyColorMap(np.uint8(255*heatmap), cv2.COLORMAP_JET), 0.4, 0)])
        cv2.putText(res_img, f"GT:{labels.item()} P:{pred} ({prob_tb:.1%})", (5, 20), 4, 0.5, (255,255,255), 1)
        cv2.imwrite(os.path.join(CAM_SAVE_DIR, f"{fname[0]}_cam.png"), res_img)
        
        results.append({"File": fname[0], "GT": labels.item(), "Pred": pred, "Prob": prob_tb})

    acc = accuracy_score(labels_list, preds_list)
    auc = roc_auc_score(labels_list, probs_list) if len(set(labels_list)) > 1 else 0
    tn, fp, fn, tp = confusion_matrix(labels_list, preds_list).ravel()
    sen, spe = tp/(tp+fn), tn/(tn+fp)
    
    print(f"\nğŸ“Š Final Result - ACC: {acc:.3f}, AUC: {auc:.3f}, SEN: {sen:.3f}, SPE: {spe:.3f}")
    pd.DataFrame(results).to_excel(EXCEL_SAVE_PATH, index=False)

def main():
    transform = transforms.Compose([transforms.Resize((IMG_SIZE, IMG_SIZE)), transforms.ToTensor(),
                                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])
    
    full_ds = CXRDataset(DATA_ROOT, transform, 'train')
    train_ds, val_ds = create_balanced_split(full_ds, val_count_per_class=250)
    test_ds = CXRDataset(DATA_ROOT, transform, 'test')
    
    print(f"ğŸ” ë°ì´í„°ì…‹: Train {len(train_ds)}, Val {len(val_ds)}, Test {len(test_ds)}")
    
    train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)
    val_dl = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)
    test_dl = DataLoader(test_ds, batch_size=1, shuffle=False)
    
    model = models.resnet50(pretrained=True)
    model.fc = nn.Linear(model.fc.in_features, 2)
    model = model.to(DEVICE)
    
    # í•™ìŠµ ì‹¤í–‰ (Patience ì„¤ì •)
    train_model(model, train_dl, val_dl, nn.CrossEntropyLoss(), 
                optim.Adam(model.parameters(), lr=LEARNING_RATE), 
                NUM_EPOCHS, patience=PATIENCE)
    
    # í•™ìŠµ ì¢…ë£Œ í›„ Best Model ë¡œë“œí•˜ì—¬ í‰ê°€
    if os.path.exists(MODEL_SAVE_PATH):
        model.load_state_dict(torch.load(MODEL_SAVE_PATH))
        print("âœ… Best Model ë¡œë“œ ì™„ë£Œ")
    
    evaluate(model, test_dl)

if __name__ == "__main__":
    main()